{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(20,20))\n",
    "for i in range(6):\n",
    "    ax = fig.add_subplot(1,6, i+1, xticks=[], yticks=[])\n",
    "    ax.imshow(x_train[i], cmap=\"gray\")\n",
    "    ax.set_title(str(y_train[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preproccessing and data exploration\n",
    "One-hot encode y_train og y_test. \n",
    "Set features to between 0-1 by dividing with 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "[5 0 4 1]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "(28, 28, 1)\n",
      "[[[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.01176471]\n",
      "  [0.07058824]\n",
      "  [0.07058824]\n",
      "  [0.07058824]\n",
      "  [0.49411765]\n",
      "  [0.53333336]\n",
      "  [0.6862745 ]\n",
      "  [0.10196079]\n",
      "  [0.6509804 ]\n",
      "  [1.        ]\n",
      "  [0.96862745]\n",
      "  [0.49803922]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.11764706]\n",
      "  [0.14117648]\n",
      "  [0.36862746]\n",
      "  [0.6039216 ]\n",
      "  [0.6666667 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.88235295]\n",
      "  [0.6745098 ]\n",
      "  [0.99215686]\n",
      "  [0.9490196 ]\n",
      "  [0.7647059 ]\n",
      "  [0.2509804 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.19215687]\n",
      "  [0.93333334]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.9843137 ]\n",
      "  [0.3647059 ]\n",
      "  [0.32156864]\n",
      "  [0.32156864]\n",
      "  [0.21960784]\n",
      "  [0.15294118]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.07058824]\n",
      "  [0.85882354]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.7764706 ]\n",
      "  [0.7137255 ]\n",
      "  [0.96862745]\n",
      "  [0.94509804]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.3137255 ]\n",
      "  [0.6117647 ]\n",
      "  [0.41960785]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.8039216 ]\n",
      "  [0.04313726]\n",
      "  [0.        ]\n",
      "  [0.16862746]\n",
      "  [0.6039216 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.05490196]\n",
      "  [0.00392157]\n",
      "  [0.6039216 ]\n",
      "  [0.99215686]\n",
      "  [0.3529412 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.54509807]\n",
      "  [0.99215686]\n",
      "  [0.74509805]\n",
      "  [0.00784314]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.04313726]\n",
      "  [0.74509805]\n",
      "  [0.99215686]\n",
      "  [0.27450982]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.13725491]\n",
      "  [0.94509804]\n",
      "  [0.88235295]\n",
      "  [0.627451  ]\n",
      "  [0.42352942]\n",
      "  [0.00392157]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.31764707]\n",
      "  [0.9411765 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.46666667]\n",
      "  [0.09803922]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.1764706 ]\n",
      "  [0.7294118 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.5882353 ]\n",
      "  [0.10588235]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.0627451 ]\n",
      "  [0.3647059 ]\n",
      "  [0.9882353 ]\n",
      "  [0.99215686]\n",
      "  [0.73333335]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.9764706 ]\n",
      "  [0.99215686]\n",
      "  [0.9764706 ]\n",
      "  [0.2509804 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.18039216]\n",
      "  [0.50980395]\n",
      "  [0.7176471 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.8117647 ]\n",
      "  [0.00784314]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.15294118]\n",
      "  [0.5803922 ]\n",
      "  [0.8980392 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.98039216]\n",
      "  [0.7137255 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.09411765]\n",
      "  [0.44705883]\n",
      "  [0.8666667 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.7882353 ]\n",
      "  [0.30588236]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.09019608]\n",
      "  [0.25882354]\n",
      "  [0.8352941 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.7764706 ]\n",
      "  [0.31764707]\n",
      "  [0.00784314]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.07058824]\n",
      "  [0.67058825]\n",
      "  [0.85882354]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.7647059 ]\n",
      "  [0.3137255 ]\n",
      "  [0.03529412]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.21568628]\n",
      "  [0.6745098 ]\n",
      "  [0.8862745 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.95686275]\n",
      "  [0.52156866]\n",
      "  [0.04313726]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.53333336]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.83137256]\n",
      "  [0.5294118 ]\n",
      "  [0.5176471 ]\n",
      "  [0.0627451 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "np\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "num_classes = 10\n",
    "input_shape = x_train.shape\n",
    "print(input_shape)\n",
    "print(y_train[0:4])\n",
    "#print(x_train[0])\n",
    "\n",
    "y_train, y_test = to_categorical(y_train, num_classes), to_categorical(y_test, num_classes)\n",
    "print(y_train[1])\n",
    "\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_train = x_train.reshape((x_train.shape[0],28,28,1))\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))\n",
    "\n",
    "input_shape = x_train[0].shape\n",
    "print(x_train[0].shape)\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 16)        80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 64)          8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               288500    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 303,926\n",
      "Trainable params: 303,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16,kernel_size=2, padding='same', activation=\"relu\", input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32,kernel_size=2, padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=2, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation=\"relu\"))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 30s 493us/step - loss: 0.9094 - acc: 0.7087 - val_loss: 0.3485 - val_acc: 0.8945\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 26s 428us/step - loss: 0.2816 - acc: 0.9112 - val_loss: 0.1683 - val_acc: 0.9474\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 27s 453us/step - loss: 0.1783 - acc: 0.9432 - val_loss: 0.1153 - val_acc: 0.9631\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 27s 456us/step - loss: 0.1237 - acc: 0.9608 - val_loss: 0.0838 - val_acc: 0.9736\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 29s 482us/step - loss: 0.1000 - acc: 0.9680 - val_loss: 0.0658 - val_acc: 0.9800\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 25s 416us/step - loss: 0.0778 - acc: 0.9752 - val_loss: 0.0776 - val_acc: 0.9733\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 33s 549us/step - loss: 0.0683 - acc: 0.9780 - val_loss: 0.0551 - val_acc: 0.9820\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 37s 612us/step - loss: 0.0571 - acc: 0.9819 - val_loss: 0.0465 - val_acc: 0.9841\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 33s 553us/step - loss: 0.0476 - acc: 0.9848 - val_loss: 0.0379 - val_acc: 0.9871\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 31s 512us/step - loss: 0.0424 - acc: 0.9861 - val_loss: 0.0637 - val_acc: 0.9788\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 26s 438us/step - loss: 0.0357 - acc: 0.9887 - val_loss: 0.0439 - val_acc: 0.9845\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 23s 377us/step - loss: 0.0318 - acc: 0.9900 - val_loss: 0.0307 - val_acc: 0.9893\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 27s 449us/step - loss: 0.0280 - acc: 0.9909 - val_loss: 0.0414 - val_acc: 0.9876\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 32s 533us/step - loss: 0.0241 - acc: 0.9921 - val_loss: 0.0511 - val_acc: 0.9845\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 29s 488us/step - loss: 0.0218 - acc: 0.9928 - val_loss: 0.0329 - val_acc: 0.9888\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 31s 522us/step - loss: 0.0189 - acc: 0.9938 - val_loss: 0.0342 - val_acc: 0.9881\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 31s 520us/step - loss: 0.0168 - acc: 0.9945 - val_loss: 0.0332 - val_acc: 0.9889\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 23s 385us/step - loss: 0.0154 - acc: 0.9949 - val_loss: 0.0318 - val_acc: 0.9896\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 25s 418us/step - loss: 0.0141 - acc: 0.9954 - val_loss: 0.0361 - val_acc: 0.9889\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 23s 377us/step - loss: 0.0131 - acc: 0.9958 - val_loss: 0.0346 - val_acc: 0.9887\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 22s 366us/step - loss: 0.0109 - acc: 0.9966 - val_loss: 0.0368 - val_acc: 0.9897\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 23s 377us/step - loss: 0.0098 - acc: 0.9969 - val_loss: 0.0410 - val_acc: 0.9872\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 24s 392us/step - loss: 0.0085 - acc: 0.9971 - val_loss: 0.0430 - val_acc: 0.9881\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 23s 379us/step - loss: 0.0083 - acc: 0.9974 - val_loss: 0.0316 - val_acc: 0.9899\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 22s 362us/step - loss: 0.0073 - acc: 0.9977 - val_loss: 0.0334 - val_acc: 0.9907\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 23s 377us/step - loss: 0.0082 - acc: 0.9973 - val_loss: 0.0383 - val_acc: 0.9903\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 22s 359us/step - loss: 0.0052 - acc: 0.9985 - val_loss: 0.0313 - val_acc: 0.9910\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 22s 362us/step - loss: 0.0066 - acc: 0.9980 - val_loss: 0.0302 - val_acc: 0.9913\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 22s 372us/step - loss: 0.0053 - acc: 0.9986 - val_loss: 0.0330 - val_acc: 0.9918\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 22s 371us/step - loss: 0.0059 - acc: 0.9981 - val_loss: 0.0352 - val_acc: 0.9909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0a85356fd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=1000, epochs=30, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mnist.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
